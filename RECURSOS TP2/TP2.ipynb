{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b41b147-695b-447c-860f-c5fb86aa2b97",
   "metadata": {},
   "source": [
    "# Punto 1: Autovectores y autovalores de L y R\n",
    "## Punto a\n",
    "Muestren que el vector de unos $1$ es autovector de las matrices $R$ y $L$. ¿Qué autovalor tiene? ¿Y qué agrupación de la red representa?\n",
    "### Respuesta\n",
    "Considerando la matriz laplaciana $L=K-A$, donde:\n",
    "- $K$ la matriz diagonal de grados del grafo, definida como $K=\\text{diag}(k_1,k_2,...,k_n)$, donde cada $k_i=\\sum_jA_{ij}$ representa el grado del nodo $i$.\n",
    "- $A$ es la matriz de adyacencia del grafo, que asumimos no dirigido y sin lazos, por lo que es simétrica y tiene ceros en la diagonal.\n",
    "Al evaluar la acción de $L$ sobre el vector $1$ tenemos que\n",
    "$$L\\cdot1=(K-A)\\cdot1=K\\cdot1-A\\cdot1$$\n",
    "Dado que $K\\cdot1=(k_1,...,k_n)^t$ y $A\\cdot1=(k_1,...,k_n)^t$, se concluye que:\n",
    "$$L\\cdot1=0$$\n",
    "Por lo tanto, el vector $1$ es autovector de $L$ con autovalor $\\lambda=0$.\n",
    "Este autovector trivial representa la agrupación en la que todos los nodos de la red pertenecen a un único grupo, es decir, **sin partición**.\n",
    "Luego, probamos que $1$ es autovector de $R$ utilizando la matriz de modularidad $R=A-P$ donde $P$ es la matriz que representa las conexiones esperadas entre nodos bajo el **modelo de configuración**, y se define como:\n",
    "$$P_{ij}=\\frac{k_ik_j}{2E}$$\n",
    "donde $E=\\frac{1}{2}\\sum_{i,j}A_{ij}$ es el número total de enlaces en la red. Entonces, el producto de $P$ por el vector $1$ da:\n",
    "$$(P\\cdot1)_i=\\sum_j\\frac{k_ik_j}{2E}=\\frac{k_i}{2E}\\sum_jk_j=\\frac{k_i\\cdot2E}{2E}=k_i$$\n",
    "Dado que $A\\cdot1=(k_1,...,k_n)^t$, tenemos que:\n",
    "$$R\\cdot1=(A-P)\\cdot1=A\\cdot1-P\\cdot1=(k_1,...,k_n)^t-(k_1,...,k_n)^t=0$$\n",
    "Por lo tanto, el vector $1$ también es autovector de la matriz $R$, con autovalor $\\lambda=0$.\n",
    "Tal como en el caso anterior, este autovector representa la no-partición: una configuración en la que todos los nodos de la red son asignados al mismo grupo.\n",
    "## Punto b\n",
    "Muestren que si $L(R)$ tienen dos autovectores $v_1$ y $v_2$ asociados a autovalores $\\lambda_1\\neq\\lambda_2$, entonces $v_1^tv_2=0$. *Tip: Consideren una matriz $M$ simétrica con dos autovectores $v_1$ y $v_2$ con autovalores distintos $\\lambda_1$ y $\\lambda_2$. Comparen el resultado de hacer $v_1^tMv_2$ y $v_2^tMv_1$.*\n",
    "### Respuesta\n",
    "Sea $M\\in\\mathbb{R}^{n\\times n}$ una matriz simétrica (al igual que son $L$ o $R$). Supongamos que $v_1$ y $v_2$ son autovectores de $M$ asociados a autovalores $\\lambda_1$ y $\\lambda_2$ respectivamente, con $\\lambda_1\\neq\\lambda_2$. Se quiere demostrar que $v_1^tv_2=0$.\n",
    "Dado que $v_1$ y $v_2$ son autovectores, se cumple que\n",
    "$$Mv_1=\\lambda_1v_1,\\quad Mv_2=\\lambda_2v_2$$\n",
    "Multiplicando escalarmente la primera ecuación por $v_2^t$ tenemos que:\n",
    "$$v_2^tMv_1=\\lambda_1v_2^tv_1$$\n",
    "Análogamente, al multiplicar la segunda ecuación por $v_1^t$ obtenemos\n",
    "$$v_1^tMv_2=\\lambda_2v_1^tv_2$$\n",
    "Ahora bien, utilizando la simetría de $M$, se tiene que:\n",
    "$$v_2^tMv_1=v_1^tMv_2$$\n",
    "Por lo tanto, las dos expresiones anteriores implican que\n",
    "$$\\lambda_1v_2^tv_1=\\lambda_2v_1^tv_2$$\n",
    "Dado que el producto escalar es simétrico, es decir $v_1^tv_2=v_2^tv_1$, se obtiene que\n",
    "$$\\lambda_1v_1^tv_2=\\lambda_2v_1^tv_2$$\n",
    "De lo cual deducimos que\n",
    "$$(\\lambda_1-\\lambda_2)v_1^tv_2=0$$\n",
    "Como inicialmente asumimos que $\\lambda_1\\neq\\lambda_2$, se concluye que $v_1^tv_2=0$. Por lo tanto, los autovectores correspondientes a autovalores distintos de una matriz simétrica son ortogonales. En particular, esto se cumple para las matrices $L$ y $R$, ya que ambas son simétricas.\n",
    "## Punto c\n",
    "Muestren si $v$ es un autovector de autovalor $\\lambda\\neq0$ de $R$ o $L$, entonces $\\sum_iv_i=0$.\n",
    "### Respuesta\n",
    "Sea $v\\in\\mathbb{R}^n$ un autovector asociado al autovalor $\\lambda=0$ de una de las matrices simétricas consideradas, $L$ o $R$. Se busca determinar si necesariamente se cumple que $\\sum_{i=1}^{n}v_i=0$.\n",
    "Primero consideramos la matriz laplaciana $L=K−A$. Como se demostró previamente, el vector $1=(1,\\dots,1)^t$ es autovector de $L$ con autovalor $\\lambda=0$. Si la red es conexa, el subespacio nulo de $L$ es unidimensional, por lo que cualquier autovector asociado a $\\lambda=0$ es múltiplo escalar de $1$. En tal caso, su suma es $\\sum_iv_i=c\\cdot n$, con $c\\neq0$, y por lo tanto:\n",
    "$$\\sum_{i=1}^nv_i\\neq0$$\n",
    "Luego, la afirmación resulta falsa para $L$ si se interpreta como una propiedad general: existen autovectores con $\\lambda=0$ cuya suma no es nula.\n",
    "En el caso de la matriz de modularidad $R=A−P$, también se tiene que $R\\cdot1=0$, por lo que $1$ es nuevamente un autovector asociado a $\\lambda=0$, con suma no nula. Sin embargo, a diferencia de la matriz laplaciana, la matriz $R$ puede presentar un núcleo de dimensión mayor a uno, dependiendo de la estructura de la red. En este caso, pueden existir autovectores $v\\in\\ker(R)$ tales que $\\sum_iv_i=0$.\n",
    "Es decir, si $v\\in\\ker(R)$ y $v\\perp1$, entonces necesariamente $\\sum_iv_i=1^t v=0$. De hecho, en aplicaciones prácticas, tales autovectores ortogonales a $1$ son útiles en tareas de partición espectral, ya que codifican divisiones balanceadas entre grupos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a13b86-07fb-4e27-a524-b1d523376e52",
   "metadata": {},
   "source": [
    "# Ejercicio 2: Extensiones del método de la potencia\n",
    "Consideren una matriz $M\\in\\mathbb{R}^{n\\times n}$ diagonalizable con autovalores $\\lambda_1\\geq\\lambda_2\\geq\\cdots\\geq\\lambda_n$, y autovector $v_i$ asociado a $\\lambda_i$.\n",
    "## Punto a: Shifting de autovalores\n",
    "Muestre que los autovalores de $M+\\mu I$ son $\\gamma_i=\\lambda_i+\\mu$, y que el autovector asociado a $\\gamma_i$ es $v_i$. Concluya que si $\\mu+\\lambda_i\\neq0,\\forall i$, entonces $M+\\mu I$ es inversible.\n",
    "### Respuesta\n",
    "Si definimos la matriz $M_\\mu=M+\\mu I,\\mu\\in\\mathbb{R}$ tenemos que\n",
    "$$M_\\mu v_i=(M+\\mu I)v_i)=Mv_i+\\mu v_i=(\\lambda_i+\\mu)v_i$$\n",
    "Por lo tanto, los autovalores de $M_\\mu$ son\n",
    "$$\\gamma_i=\\lambda_i+\\mu,\\quad1\\leq i\\leq n$$\n",
    "y cada $v_i$ sigue siendo su autovector asociado.\n",
    "Además, si consideramos que $\\mu+\\lambda_i\\neq 0,\\forall i$, entonces $\\gamma_i\\neq0,\\forall i$. En consecuencia\n",
    "$$\\det(M_\\mu)=\\prod_{i=1}^n\\gamma_i\\neq0$$\n",
    "En conclusión, $M_\\mu$ es inversible.\n",
    "## Punto b: Método de la potencia inverso\n",
    "Considerando $\\mu>0$, muestren que $L+\\mu I$ es inversible, con $L$ el laplaciano definido como $L=K-A$. Muestren que aplicar el método de la potencia a $(L+\\mu I)^{-1}$ converge a su autovector de autovalor más chico si se parte de una semilla adecuada. Indique, en el caso de que hay sólo un autovector con dicho autovalor, cuál es dicho autovector y cuánto vale su autovalor.\n",
    "### Respuesta\n",
    "Analizando la matriz laplaciana $L=K-A$, donde $K$ es la matriz diagonal de grados y $A$ la matriz de adyacencia de un grafo no dirigido y sin lazos, podemos determinar que $L$ es simétrica, pues ambas matrices que la componen lo son. Entonces, tenemos que sus autovalores son reales, pero debemos determinar que dicha matriz resulte semidefinida positiva para abordar el análisis de inversibilidad de la matriz $L_\\mu=L+\\mu I$.\n",
    "#### $L$ es semidefinida positiva\n",
    "Para demostrar que $L$ es semidefinida positiva, debemos demostrar que para todo vector $x\\in\\mathbb{R}^n$, se cumple la desigualdad $x^tLx\\geq0$. Entonces, partiendo de esta expresión y la definición de $L$ tenemos que\n",
    "$$x^tLx=x^t(K-A)x=X^tKx-x^tAx$$\n",
    "La primera parte puede desarrollarse utilizando que $K$ es diagonal\n",
    "$$x^tKx=\\sum_{i=1}^nk_ix_i^2$$\n",
    "donde $k_i\\sum_jA_{ij}$ es el grado del nodo $i$. Luego, siendo $A$ simétrica, obtenemos la siguiente igualdad para el segundo término:\n",
    "$$x^tAx=\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}x_ix_j$$\n",
    "Sustituyendo las expresiones halladas obtenemos\n",
    "$$x^tLx=\\sum_{i=1}^nk_ix_i^2-\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}x_ix_j$$\n",
    "Como $k_i=\\sum_j A_{ij}$, podemos reescribir el primer término como\n",
    "$$x^tLx=\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}x_i^2-\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}x_ix_j$$\n",
    "Y como $A_{ij}$ es un factor común en cada término tenemos que\n",
    "$$x^tLx=\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}(x_i^2-x_ix_j)$$\n",
    "Como la matriz de adyacencia es simétrica y $A_{ij}=A_{ji}$, reescribimos la expresión de manera simétrica, intercambiando índices y promediando ambos términos.\n",
    "$$x^tLx=\\frac{1}{2}\\sum_{i=1}^n\\sum_{j=1}^nA_{ij}(x_i-x_j)^2$$\n",
    "Esto es posible pues\n",
    "$$(x_i-x_j)^2=x_i^2-2x_ix_j+x_j^2=(x_i^2-x_ix_j)+(x_j^2-x_jx_i)$$\n",
    "y dada la simetría de $A_{ij}$ se garantiza que la suma sobre $i,j$ y sobre $j,i$ son iguales. De modo que se obtiene la expresión dada anteriormente para $x^tLx$.\n",
    "Como cada término de la suma es no negativo (ya que los términos están compuesto por un cuadrado, y los pesos $A_{ij}\\geq0$ por definición), la sumatoria es no negativa para todo $x$, demostrando que $L$ es una matriz semidefinida positiva. Por lo tanto, concluimos que\n",
    "$$x^tLx\\geq0,\\forall x\\in\\mathbb{R}^n$$\n",
    "#### Análisis de $L_\\mu$\n",
    "Puesto que $L$ es semidefinida positiva, tenemos que $\\lambda_i(L)\\geq0,1\\leq i\\leq n$. En particular, como el grafo es conexo, el autovalor nulo es simple y tiene como único autovector al vector $1$.\n",
    "Ahora, considerando $\\mu>0$, y el resultado obtenido en el punto a del presente ejercicio, deducimos que los autovalores de $L_\\mu$ son $\\lambda_i+\\mu$, todos estrictamente positivos dada la suposición inicial sobre $\\mu$. Por lo tanto, tenemos que\n",
    "$$\\det(L_\\mu)=\\prod_{i=1}^n(\\lambda_i+\\mu)\\neq0$$\n",
    "En conclusión, $L_\\mu$ resulta inversible.\n",
    "Definiendo $B=L_\\mu^{-1}$, como tenemos que la misma base ortonormal de autovectores $\\{w_i\\}$ de $L$ diagonaliza a $B$, pero ahora con autovalores $\\rho_i=\\frac{1}{\\lambda_i+\\mu}$. Considerando que $\\lambda_n=0$, el mayor autovalor de $B$ resulta ser $\\rho_n=\\frac{1}{\\mu}$ y está asociado al autovector $w_n=\\frac{1}{\\sqrt{n}}$. De este modo, el resto de autovalores $\\rho_i<\\rho_n$.\n",
    "El método de la potencia aplicado a una matriz real simétrica converge hacia el autovector que corresponde al autovalor de mayor módulo siempre que el vector inicial posea proyección distinta de cero sobre dicha dirección. En este caso, escoger cualquier $x^{(0)}\\not\\!\\perp1$ garantiza que la sucesión iterativa $x^{(k+1)}=\\frac{Bx^{(k)}}{\\|Bx^{(k)}\\|_2}$ tiende a $\\frac{1}{\\sqrt{n}}$​. De este modo, la razón de convergencia es $\\frac{\\rho_{n-1}}{\\rho_n}=\\frac{\\mu}{\\lambda_{n-1}+\\mu}<1$. Así, la potencia inversa sobre $L_\\mu$​ identifica el autovector correspondiente al autovalor mínimo de $L$, que en un grafo conexo es único y vale precisamente $1$, mientras que el autovalor asociado es $\\lambda_{\\min}(L)=0$. En consecuencia, se ha mostrado la invertibilidad de $L+\\mu I$ para todo $\\mu>0$, la convergencia del método de la potencia aplicado a su inversa hacia el autovector del autovalor más pequeño, y, cuando dicho autovalor es simple, se ha determinado explícitamente tanto el autovector ($1$) como el valor propio correspondiente ($0$).\n",
    "## Punto c: Deflación de Hotelling\n",
    "Suponiendo que $M$ es simétrica (y por lo tanto admite una base ortogonal de autovectores), muestre que la matriz $\\tilde{M}-\\lambda_1\\frac{v_1v_1^t}{v_1^tv_1}$ tiene los mismos autovectores que $M$, pero el autovalor asociado a $v_1$ es igual a cero.\n",
    "### Respuesta\n",
    "Sea $M\\in\\mathbb{R}^{n\\times n}$ una matriz simétrica. Por el teorema espectral, se sabe que toda matriz simétrica es diagonalizable mediante una base ortonormal de autovectores. Esto significa que existen $n$ vectores $\\{v_1,v_2,\\dots,v_n\\}\\subset\\mathbb{R}^n$, ortogonales entre sí, tales que para cada $i\\in\\{1,\\dots,n\\}$, se cumple M $v_i=\\lambda_iv_i$, donde $\\lambda_i\\in\\mathbb{R}$ es el autovalor correspondiente. Supóngase, sin pérdida de generalidad, que $\\lambda_1$ es el autovalor de mayor módulo, y que $v_1$ es el autovector correspondiente.\n",
    "Con el objetivo de eliminar la contribución del autovalor dominante $\\lambda_1$ del espectro de $M$, se define la matriz modificada\n",
    "$$\\tilde{M}=M-\\lambda_1\\frac{v_1v_1^t}{v_1^tv_1}$$\n",
    "y se desea demostrar que $\\tilde{M}$ conserva los mismos autovectores que $M$, pero que el autovalor asociado a $v_1$ pasa a ser cero.\n",
    "Para proceder con la demostración, se analiza la acción de $\\tilde{M}$ sobre un vector arbitrario $v_i$ de la base ortogonal de autovectores de $M$. Primero se considera el caso en que $v_i=v_1$. Dado que $v_1$ es un autovector de $M$, se cumple $M v_1=\\lambda_1v_1$, y por lo tanto:\n",
    "$$\\tilde{M}v_1=Mv_1-\\lambda_1\\frac{v_1v_1^t}{v_1^t v_1}v_1=\\lambda_1v_1-\\lambda_1\\frac{v_1(v_1^t v_1)}{v_1^t v_1}=\\lambda_1v_1-\\lambda_1v_1=0$$\n",
    "Por consiguiente, $v_1$ sigue siendo autovector de $\\tilde{M}$, pero ahora asociado al autovalor $0$.\n",
    "A continuación, se considera el caso general $v_i$, con $i\\neq1$. Como $\\{v_i\\}$ es una base ortogonal de autovectores de $M$, se cumple $Mv_i=\\lambda_iv_i$, y además $v_1^tv_i=0$. Evaluando $\\tilde{M}v_i$, se tiene:\n",
    "$$\\tilde{M}v_i=Mv_i-\\lambda_1\\frac{v_1 v_1^t}{v_1^t v_1}v_i=\\lambda_iv_i-\\lambda_1\\frac{v_1 (v_1^t v_i)}{v_1^t v_1}=\\lambda_iv_i-\\lambda_1\\cdot\\frac{v_1\\cdot0}{v_1^t v_1}=\\lambda_iv_i$$\n",
    "De este modo, para todo $i\\neq1$, $v_i$ continúa siendo autovector de $\\tilde{M}$, con el mismo autovalor que tenía en $M$. Se concluye entonces que la matriz $\\tilde{M}$ tiene exactamente la misma base ortonormal de autovectores que $M$, pero el autovalor asociado a $v_1$ ha sido reemplazado por cero. El espectro de $\\tilde{M}$ consiste en $\\{0,\\lambda_2,\\dots,\\lambda_n\\}$, respetando las multiplicidades de los autovalores restantes.\n",
    "Este procedimiento se conoce como **deflación de Hotelling**, y constituye una herramienta fundamental para eliminar del análisis espectral la contribución del autovalor dominante, permitiendo aplicar métodos iterativos como la potencia para hallar sucesivamente los autovectores asociados a autovalores secundarios. En el contexto del presente trabajo, esta técnica permite acceder al segundo autovalor más pequeño de la matriz laplaciana $L$, o al segundo autovalor más grande de la matriz de modularidad $R$, al eliminar previamente la influencia del vector trivial asociado a $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31e12f7-40ec-4b57-a8ef-47432cf748c8",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa745e-460d-4d58-9283-a0174ba44ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos librerías\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.linalg import solve_triangular\n",
    "import geopandas as gpd\n",
    "\n",
    "# Cargamos funciones auxiliares\n",
    "\n",
    "# Función para permutar filas (para descompPLU)\n",
    "def permutacion(A, vector_P, index):\n",
    "    n = A.shape[0]\n",
    "    max_index = index + np.argmax(np.abs(A[index:, index]))\n",
    "    #swap\n",
    "    if max_index != index:\n",
    "        A[[index, max_index]] = A[[max_index, index]]\n",
    "        vector_P[[index, max_index]] = vector_P[[max_index, index]]\n",
    "\n",
    "\n",
    "# Descomposición PLU con pivoteo\n",
    "def calculaPLU(m, verbose=False):\n",
    "    mc = m.copy().astype(np.float64)\n",
    "    n = m.shape[0]\n",
    "    P = np.eye(n)\n",
    "    for i in range(n - 1):\n",
    "        max_row = i + np.argmax(np.abs(mc[i:, i]))\n",
    "        if max_row != i:\n",
    "            mc[[i, max_row]] = mc[[max_row, i]]\n",
    "            P[[i, max_row]] = P[[max_row, i]]\n",
    "        a_ii = mc[i, i]\n",
    "        if a_ii == 0:\n",
    "            raise ValueError(\"Matriz singular (no invertible)\")\n",
    "        L_i = mc[i+1:, i] / a_ii\n",
    "        mc[i+1:, i] = L_i\n",
    "        mc[i+1:, i+1:] -= np.outer(L_i, mc[i, i+1:])\n",
    "    \n",
    "    L = np.tril(mc, -1) + np.eye(n)\n",
    "    U = np.triu(mc)\n",
    "    if verbose:\n",
    "        print(\"P:\\n\", P)\n",
    "        print(\"L:\\n\", L)\n",
    "        print(\"U:\\n\", U)\n",
    "    return P, L, U\n",
    "\n",
    "\n",
    "def calculaLU(matriz, verbose=False):\n",
    "    mc = matriz.copy().astype(np.float64)\n",
    "    n = matriz.shape[0]\n",
    "    for i in range(n - 1):\n",
    "        a_ii = mc[i, i]\n",
    "        if a_ii == 0:\n",
    "            raise ValueError(\"Cero en la diagonal durante LU (se requiere pivoteo)\")\n",
    "        L_i = mc[i+1:, i] / a_ii\n",
    "        mc[i+1:, i] = L_i\n",
    "        mc[i+1:, i+1:] -= np.outer(L_i, mc[i, i+1:])\n",
    "    \n",
    "    L = np.tril(mc, -1) + np.eye(n)\n",
    "    U = np.triu(mc)\n",
    "    if verbose:\n",
    "        print(\"L:\\n\", L)\n",
    "        print(\"U:\\n\", U)\n",
    "    return L, U\n",
    "\n",
    "# Función para calcular la inversa corregida\n",
    "def inversa(m):\n",
    "    n = m.shape[0]\n",
    "    try:\n",
    "        L, U = calculaLU(m)\n",
    "        P = np.eye(n)  # Matriz de permutación identidad si no hay pivoteo\n",
    "    except (ValueError, np.LinAlgError):\n",
    "        P, L, U = calculaPLU(m)\n",
    "    \n",
    "    m_inv = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        e_i = P.T @ np.eye(n)[:, i]  # Aplica la permutación P al vector canónico\n",
    "        y = solve_triangular(L, e_i, lower=True)\n",
    "        x = solve_triangular(U, y, lower=False)\n",
    "        m_inv[:, i] = x\n",
    "    return m_inv\n",
    "\n",
    "def calcula_K (A):\n",
    "    n = A.shape[0]\n",
    "    k = np.zeros((n,n),dtype=A.dtype)\n",
    "    for i in range(n):\n",
    "        k[i][i] = A[i].sum()\n",
    "    \n",
    "    return k\n",
    "\n",
    "def norma2(v):\n",
    "    n = 0\n",
    "    for k in v:\n",
    "        n+=k*k\n",
    "    return np.sqrt(n)\n",
    "\n",
    "# Matriz de adbyacencia\n",
    "def construye_adyacencia(D,m): \n",
    "    # Función que construye la matriz de adyacencia del grafo de museos\n",
    "    # D matriz de distancias, m cantidad de links por nodo\n",
    "    # Retorna la matriz de adyacencia como un numpy.\n",
    "    D = D.copy()\n",
    "    l = [] # Lista para guardar las filas\n",
    "    for fila in D: # recorriendo las filas, anexamos vectores lógicos\n",
    "        l.append(fila<=fila[np.argsort(fila)[m]] ) # En realidad, elegimos todos los nodos que estén a una distancia menor o igual a la del m-esimo más cercano\n",
    "    A = np.asarray(l).astype(int) # Convertimos a entero\n",
    "    np.fill_diagonal(A,0) # Borramos diagonal para eliminar autolinks\n",
    "    return(A)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137b7480-459b-4c26-b9b3-0784129d4597",
   "metadata": {},
   "source": [
    "## a. Construccion de matrices\n",
    "\n",
    "### i. Matrices L y R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1761813f-8714-4c15-8634-83e32bd839fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L = K -A\n",
    "def calcula_L(A):\n",
    "    # La función recibe la matriz de adyacencia A y calcula la matriz laplaciana\n",
    "    L = calcula_K(A) - A\n",
    "    return L\n",
    "\n",
    "# P_ij número esperado de conexiones entre i y j\n",
    "# P_ij = kikj/2E  => P = k . k^t/2E\n",
    "# R = A - P\n",
    "def calcula_R(A):\n",
    "    # La funcion recibe la matriz de adyacencia A y calcula la matriz de modularidad\n",
    "    k =  np.diag(calcula_K(A)).reshape(-1, 1)\n",
    "    R = A-  1/np.sum(A) * k @ k.T\n",
    "    return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6227a09e-9dea-4697-94fd-f0fa42d89cb3",
   "metadata": {},
   "source": [
    "### Calcular $\\Lambda$ y Q asociados a _v_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3926651e-a66d-48b7-8c1a-5de9823d2e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_lambda(L,v):\n",
    "    # Recibe L y v y retorna el corte asociado\n",
    "    # definimos el vector s de signos asociado a v\n",
    "    s = np.array([-1 if x < 0 else (1 if x > 0 else 0) for x in v])\n",
    "    lambdon = s.T @ L @ s\n",
    "    return lambdon\n",
    "\n",
    "#def calcula_Q(R,v):\n",
    "    # La funcion recibe R y s y retorna la modularidad (a menos de un factor 2E)\n",
    "#    return Q\n",
    "\n",
    "def calcula_Q_(A,R,v):\n",
    "    # La funcion recibe R y s y retorna la modularidad (a menos de un factor 2E)\n",
    "    s = np.array([-1 if x < 0 else (1 if x > 0 else 0) for x in v])\n",
    "    Q = 1/(2*np.sum(A)) * s.T @ R @ s\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce4d0cb-5410-4f60-954e-4b200ce814ea",
   "metadata": {},
   "source": [
    "## Funciones para encontrar autovectores.\n",
    "\n",
    "### i. Metodo de la potencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381aeb81-86da-478c-b49f-00256d4f8b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metpot1(A,tol=1e-8,maxrep=np.Inf):\n",
    "   # Recibe una matriz A y calcula su autovalor de mayor módulo, con un error relativo menor a tol y-o haciendo como mucho maxrep repeticiones\n",
    "   v = 2 * np.random.rand(A.shape[0],1) - 1 # Generamos un vector de partida aleatorio, entre -1 y 1\n",
    "   v /= np.linalg.norm(v,2) # Lo normalizamos\n",
    "   v1 = A @ v # Aplicamos la matriz una vez\n",
    "   v1 /= np.linalg.norm(v1,2) # normalizamos\n",
    "   l = v.T @ A @ v / (v.T @ v) # autovector estimado A@v = l v1 <=> v*A@v = l v*v <=> l = v*A@v / v*v\n",
    "   l1 = v1.T @ A @ v1 / (v1.T @ v1) # Y el estimado en el siguiente paso\n",
    "   nrep = 0 # Contador\n",
    "   while np.abs(l1-l)/np.abs(l) > tol and nrep < maxrep: # Si estamos por debajo de la tolerancia buscada \n",
    "      v = v1 # actualizamos v y repetimos\n",
    "      l = l1\n",
    "      v1 = A @ v # Calculo nuevo v1\n",
    "      v1 /= np.linalg.norm(v1,2) # Normalizo\n",
    "      l1 = v1.T @ A @ v1 / (v1.T @ v1) # Calculo autovector\n",
    "      nrep += 1 # Un pasito mas\n",
    "   if not nrep < maxrep:\n",
    "      print('MaxRep alcanzado')\n",
    "   l =  l1[0][0] # Calculamos el autovalor\n",
    "   return v1,l,nrep<maxrep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535920ba-8d4e-4011-a1e6-fe9818b252e0",
   "metadata": {},
   "source": [
    "### ii. Deflación de Hotelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784a78f-cd3b-4ade-b138-f98ebfa51b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deflA = A - l v*v^t/(v^tv)\n",
    "def deflaciona(A,tol=1e-8,maxrep=np.Inf):\n",
    "    # Recibe la matriz A, una tolerancia para el método de la potencia, y un número máximo de repeticiones\n",
    "    v1,l1,_ = metpot1(A,tol,maxrep) # Buscamos primer autovector con método de la potencia\n",
    "    deflA = A - l1/(v1.T @ v1) * np.outer(v1,v1) # Sugerencia, usar la funcion outer de numpy\n",
    "    return deflA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6134caaf-757d-4730-9850-80d78b25f392",
   "metadata": {},
   "source": [
    "### iii. Metodo de la potencia inversa\n",
    "Recibe una matriz _A_ u un coeficiente $\\mu>0$ y calcula al autovalor más chico de $A + \\mu I$ junto a su autovector asociado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09727a6-b5f7-482d-b6b2-53a5423d81b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metpotI(A,mu,tol=1e-8,maxrep=np.Inf):\n",
    "    # Retorna el primer autovalor de la inversa de A + mu * I, junto a su autovector y si el método convergió.\n",
    "    M = inversa(A + mu * np.identity(A.shape[0]))\n",
    "    return metpot1(M,tol=tol,maxrep=maxrep)\n",
    "\n",
    "def metpot2(A,v1,l1,tol=1e-8,maxrep=np.Inf):\n",
    "   # La funcion aplica el metodo de la potencia para buscar el segundo autovalor de A, suponiendo que sus autovectores son ortogonales\n",
    "   # v1 y l1 son los primeros autovectores y autovalores de A}\n",
    "   deflA = deflaciona(A)\n",
    "   return metpot1(deflA,tol,maxrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a7df19-5c9e-4894-a31a-f4c199d5f034",
   "metadata": {},
   "source": [
    "### iv. \n",
    "Recibe una matriz _A_ u un coeficiente $\\mu>0$ y calcula el segundo autovalor más chico de $A + \\mu I$ junto a su autovector asociado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0f685-bc25-46d7-a5a0-f2354dbb1776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metpotI2(A,mu,tol=1e-8,maxrep=np.Inf):\n",
    "   # Recibe la matriz A, y un valor mu y retorna el segundo autovalor y autovector de la matriz A, \n",
    "   # suponiendo que sus autovalores son positivos excepto por el menor que es igual a 0\n",
    "   # Retorna el segundo autovector, su autovalor, y si el metodo llegó a converger.\n",
    "   X = A + mu * np.identity(A.shape[0]) # Calculamos la matriz A shifteada en mu\n",
    "   iX = inversa(X) # La invertimos\n",
    "   v1,l1,es_conv = metpot1(iX)\n",
    "   defliX = deflaciona(iX) # La deflacionamos\n",
    "   v,l,_ = metpot1(defliX)  # Buscamos su segundo autovector\n",
    "   l = 1/l # Reobtenemos el autovalor correcto\n",
    "   l -= mu\n",
    "   return v,l,_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c4dfca-20e0-40d2-90d8-90f84e34f88f",
   "metadata": {},
   "source": [
    "## c. Funciones que realizan particiones iterativas de los grafos\n",
    "\n",
    "### i. Corte mínimo. \n",
    "Sea una red sin dirigir representada en un grafo al cual le asociamos la matriz  $A \\in \\mathbb{R}^{N \\times N}$ para este grafo el cual representa $A_{ij}= 1$ si $i$ y $j$ están conectados y $A_{ij}= 0$ si no.  \n",
    "Podemos detectar _grupos_ en esta red. Por ejemplo para el caso más básico; queremos identificar dos grupos $G_1, G_2$. Representamos la asignación en comunidades mediante el vector **s** definido $s_i =1$ si $i \\in G_1$ y $s_i =-1$ si $i \\in G_2$. Notamos la cantidad de conexiones entre ambos grupos por $\\Lambda$\n",
    "$$\\Lambda = \\frac{1}{4} s^tLs  \\quad \\text{con } L= K -A $$\n",
    "Buscamos un vector $s^{\\Lambda}$ optimo que minimice $\\Lambda$, para ello buscamos el segundo autovector de autovalor más pequeño de la matriz _L_ . Si aplicamos el mètodo de la potencia a $L^{-1}$ el autovalor de menor valor absoluto pasa a ser el dominante. En general, aplicando el método a $(L- \\mu I)^{-1}$ con $\\mu$ cercano a $\\lambda_{N-1}$ conseguiremos que $\\lambda_{N-1}$ sea dominante "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444dd30f-ce7a-4509-b917-9ffbff5489e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplaciano_iterativo(A,niveles,nombres_s=None):\n",
    "    # Recibe una matriz A, una cantidad de niveles sobre los que hacer cortes, y los nombres de los nodos\n",
    "    # Retorna una lista con conjuntos de nodos representando las comunidades.\n",
    "    # La función debe, recursivamente, ir realizando cortes y reduciendo en 1 el número de niveles hasta llegar a 0 y retornar.\n",
    "    if nombres_s is None: # Si no se proveyeron nombres, los asignamos poniendo del 0 al N-1\n",
    "        nombres_s = range(A.shape[0])\n",
    "    if A.shape[0] == 1 or niveles == 0: # Si llegamos al último paso, retornamos los nombres en una lista\n",
    "        return([nombres_s])\n",
    "    else: # Sino:\n",
    "        L = calcula_L(A) # Recalculamos el L\n",
    "        mu = 1 # aca deberia ir una funcion para calclar un mu optimo?\n",
    "        # buscamos el segundo autovecto y autovalor más chico, por lo que usaremos la potencia inversa, tengamos en cuenta\n",
    "        v,l,_ = metpotI2(L, mu) # Encontramos el segundo autovector de L\n",
    "        # Recortamos A en dos partes, la que está asociada a el signo positivo de v y la que está asociada al negativo\n",
    "        v = v.flatten()\n",
    "        Ap = A[v>0,:][:,v>0] # Asociado al signo positivo \n",
    "        Am = A[v<0,:][:,v<0] # Asociado al signo negativo\n",
    "        \n",
    "        return(\n",
    "                laplaciano_iterativo(Ap,niveles-1,\n",
    "                                     nombres_s=[ni for ni,vi in zip(nombres_s,v) if vi>0]) +\n",
    "                laplaciano_iterativo(Am,niveles-1,\n",
    "                                     nombres_s=[ni for ni,vi in zip(nombres_s,v) if vi<0])\n",
    "                )        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6664271-b068-4c7a-875f-f19ebe3b1aff",
   "metadata": {},
   "source": [
    "### ii. Modularidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf5e1d9-1340-446b-ab38-34ef6398ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modularidad_iterativo(A=None,R=None,nombres_s=None):\n",
    "    # Recibe una matriz A, una matriz R de modularidad, y los nombres de los nodos\n",
    "    # Retorna una lista con conjuntos de nodos representando las comunidades.\n",
    "\n",
    "    if A is None and R is None:\n",
    "        print('Dame una matriz')\n",
    "        return(np.nan)\n",
    "    if R is None:\n",
    "        R = calcula_R(A)\n",
    "    if nombres_s is None:\n",
    "        nombres_s = range(R.shape[0])\n",
    "    # Acá empieza lo bueno\n",
    "    if R.shape[0] == 1: # Si llegamos al último nivel, caso base\n",
    "        return([nombres_s])\n",
    "    else:\n",
    "        v,l,_ = metpot1(R) # Primer autovector y autovalor de R\n",
    "        v = v.flatten()\n",
    "        # Modularidad Actual:\n",
    "        Q0 = np.sum(R[v>0,:][:,v>0]) + np.sum(R[v<0,:][:,v<0])\n",
    "        if Q0<=0 or all(v>0) or all(v<0): # Si la modularidad actual es menor a cero, o no se propone una partición, terminamos\n",
    "            return([nombres_s])\n",
    "        else:\n",
    "            ## Hacemos como con L, pero usando directamente R para poder mantener siempre la misma matriz de modularidad\n",
    "            Rp  = R[v>0,:][:,v>0] # Rp Parte de R asociada a los valores positivos de v\n",
    "            Rm =  R[v<0,:][:,v<0] # Rm Parte asociada a los valores negativos de v\n",
    "            vp,lp,_ = metpot1(Rp)  # autovector principal de Rp\n",
    "            vm,lm,_ = metpot1(Rm) # autovector principal de Rm   \n",
    "            vp = vp.flatten()\n",
    "            vm = vm.flatten()\n",
    "        \n",
    "            # Calculamos el cambio en Q que se produciría al hacer esta partición\n",
    "            Q1 = 0\n",
    "            if not all(vp>0) or all(vp<0):\n",
    "               Q1 = np.sum(Rp[vp>0,:][:,vp>0]) + np.sum(Rp[vp<0,:][:,vp<0])\n",
    "            if not all(vm>0) or all(vm<0):\n",
    "                Q1 += np.sum(Rm[vm>0,:][:,vm>0]) + np.sum(Rm[vm<0,:][:,vm<0])\n",
    "            if Q0 >= Q1: # Si al partir obtuvimos un Q menor, devolvemos la última partición que hicimos\n",
    "                return([[ni for ni,vi in zip(nombres_s,v) if vi>0],[ni for ni,vi in zip(nombres_s,v) if vi<0]])\n",
    "            else:\n",
    "                # Sino, repetimos para los subniveles\n",
    "                return(\n",
    "                    modularidad_iterativo(R=Rp,\n",
    "                                          nombres_s=[ni for ni,vi in zip(nombres_s,v) if vi>0]) +\n",
    "                    modularidad_iterativo(R=Rm,\n",
    "                                          nombres_s=[ni for ni,vi in zip(nombres_s,v) if vi<0])\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271bc17b-1396-4cd2-a9c3-b2ffb63baed6",
   "metadata": {},
   "source": [
    "# 4. Particiones óptimas para la red de museos usando ambos métodos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ddc69-be5f-4b44-8aea-9bcecb2f788a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos datos\n",
    "\n",
    "museos = gpd.read_file('https://raw.githubusercontent.com/MuseosAbiertos/Leaflet-museums-OpenStreetMap/refs/heads/principal/data/export.geojson')\n",
    "barrios = gpd.read_file('https://cdn.buenosaires.gob.ar/datosabiertos/datasets/ministerio-de-educacion/barrios/barrios.geojson')\n",
    "\n",
    "# Matriz de distancias\n",
    "D = museos.to_crs(\"EPSG:22184\").geometry.apply(lambda g: museos.to_crs(\"EPSG:22184\").distance(g)).round().to_numpy()\n",
    "\n",
    "m = 3 # Cantidad de links por nodo\n",
    "A = construye_adyacencia(D,m)\n",
    "\n",
    "# Construcción de la red en NetworkX (sólo para las visualizaciones)\n",
    "G = nx.from_numpy_array(A) # Construimos la red a partir de la matriz de adyacencia\n",
    "# Construimos un layout a partir de las coordenadas geográficas\n",
    "G_layout = {i:v for i,v in enumerate(zip(museos.to_crs(\"EPSG:22184\").get_coordinates()['x'],museos.to_crs(\"EPSG:22184\").get_coordinates()['y']))}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a2f4a-cdad-4e6e-9575-edaeaeb82a7e",
   "metadata": {},
   "source": [
    "* Calcula la matriz de adyacencia simetrizada dado una matriz de distancias _D_ y un $m \\in \\mathbb{N}$\n",
    "* Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ff9c5-6ff2-4cc8-ae9f-f170635f1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_A_simetrica(D= None,m=3):\n",
    "    if D is None: print('Dame una matriz valida')\n",
    "    A = construye_adyacencia(D, m)\n",
    "    # Simetrizamos\n",
    "    A = 1/2 * (A + A.transpose())\n",
    "    return A\n",
    "\n",
    "# Funciónes auxiliares para vizualizar subgráficos\n",
    "def visualizar_comunidades_ax(museos, particiones, ax, titulo=\"Comunidades de Museos\"):\n",
    "    \"\"\"\n",
    "    Visualiza las comunidades de museos en el mapa\n",
    "    \n",
    "    Parámetros:\n",
    "    museos : GeoDataFrame con los datos de los museos\n",
    "    particiones : Lista de pd.series con índices o nombres de museos por comunidad \n",
    "    \"\"\"\n",
    "    # Creamos columna de comunidad en el GeoDataFrame copia\n",
    "    museos_plot = museos.copy()\n",
    "    museos_plot['comunidad'] = -1  # Valor por defecto\n",
    "    \n",
    "    for i, comunidad in enumerate(particiones):\n",
    "        museos_plot.loc[comunidad, 'comunidad'] = i\n",
    "    \n",
    "    # Dibuja barrios\n",
    "    barrios.boundary.plot(color='gray', ax=ax)\n",
    "    \n",
    "    # Grafica museos coloreados por comunidad\n",
    "    museos_plot.plot(column='comunidad', categorical=True, \n",
    "                    legend=True, ax=ax, markersize=50,\n",
    "                    cmap='tab20', legend_kwds={'title': \"Comunidad\"})\n",
    "    \n",
    "    ax.set_title(titulo)\n",
    "\n",
    "def visualizar_red_comunidades_ax(G, G_layout, particiones, ax, titulo=''):\n",
    "    \"\"\"\n",
    "    Visualiza la red de museos coloreada por comunidades\n",
    "    \n",
    "    Parámetros:\n",
    "    G : Grafo de NetworkX\n",
    "    G_layout : Diccionario de posiciones\n",
    "    particiones : Lista de series con índices de museos por comunidad\n",
    "    \"\"\"\n",
    "    # Asignamos colores a nodos por comunidad\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        for i, comunidad in enumerate(particiones):\n",
    "            if node in comunidad:\n",
    "                node_colors.append(i)\n",
    "                break\n",
    "    \n",
    "    # Visualización\n",
    "    nx.draw_networkx_nodes(G, G_layout, node_color=node_colors, \n",
    "                          cmap=plt.cm.tab20, node_size=100, ax=ax)\n",
    "    nx.draw_networkx_edges(G, G_layout, alpha=0.3, ax=ax)\n",
    "    nx.draw_networkx_labels(G, G_layout, font_size=8, ax=ax)\n",
    "    \n",
    "    ax.set_title(titulo)\n",
    "    \n",
    "    \n",
    "\n",
    "# Funciones para visualizar gráficos de comundades por cada metodo\n",
    "def visualizar_comparacion_comunidades(museos, G, G_layout, particiones_metodo1, particiones_metodo2, \n",
    "                                      nombre_metodo1='Método 1', nombre_metodo2='Método 2'):\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # para el método 1 \n",
    "    visualizar_comunidades_ax(museos, particiones_metodo1, axs[0], \n",
    "                                titulo=f\"{nombre_metodo1} - Comunidades en Mapa\")\n",
    "    \n",
    "    # para el método 2\n",
    "    visualizar_comunidades_ax(museos, particiones_metodo2, axs[1], \n",
    "                                titulo=f\"{nombre_metodo2} - Comunidades en Mapa\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def visualizar_comparacion_redes(G, G_layout, particiones_metodo1, particiones_metodo2, \n",
    "                                nombre_metodo1='Método 1', nombre_metodo2='Método 2'):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "    \n",
    "    # para el método 1\n",
    "    visualizar_red_comunidades_ax(G, G_layout, particiones_metodo1, axs[0], \n",
    "                                    titulo=f\"{nombre_metodo1} - Red de Comunidades\")\n",
    "    \n",
    "    # para el método 2\n",
    "    visualizar_red_comunidades_ax(G, G_layout, particiones_metodo2, axs[1], \n",
    "                                    titulo=f\"{nombre_metodo2} - Red de Comunidades\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c4d957-c009-4422-bade-12091933a4e7",
   "metadata": {},
   "source": [
    "Basado en la red de museos del TP1 calculamos las particiones óptimas usando ambos metodos. Utizamos la matriz de abyacencia _A_ simetrizada y usando diferentes valores de _m_.\n",
    "\n",
    "Para $m=3$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ed904-3f2e-4829-a3ef-e2494503fa33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
